#!/usr/bin/env python3
"""
æ¤œç´¢å±¥æ­´å‰Šé™¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
scripts/cleanup_search_history.py

æŒ‡å®šã—ãŸæœŸé–“ã‚ˆã‚Šå¤ã„æ¤œç´¢å±¥æ­´ã‚’å‰Šé™¤ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚µã‚¤ã‚ºã‚’ç®¡ç†ã™ã‚‹
"""
import sys
import os
import argparse
from datetime import datetime, timedelta

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
sys.path.insert(0, project_root)

from core.database import fetch_dict, execute_query, DB_TYPE
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

class SearchHistoryCleanup:
    def __init__(self):
        self.db_type = DB_TYPE
        self.stats = {
            'total_before': 0,
            'total_after': 0,
            'deleted_count': 0,
            'companies_affected': []
        }
    
    def get_statistics(self, company_id=None):
        """
        ç¾åœ¨ã®å±¥æ­´çµ±è¨ˆã‚’å–å¾—
        
        Args:
            company_id (str, optional): ç‰¹å®šä¼æ¥­ã®çµ±è¨ˆã‚’å–å¾—
            
        Returns:
            dict: çµ±è¨ˆæƒ…å ±
        """
        try:
            if company_id:
                # ç‰¹å®šä¼æ¥­ã®çµ±è¨ˆ
                total_query = "SELECT COUNT(*) as total FROM search_history WHERE company_id = ?"
                if self.db_type == "postgresql":
                    total_query = "SELECT COUNT(*) as total FROM search_history WHERE company_id = %s"
                
                total_result = fetch_dict(total_query, (company_id,))
                total_count = total_result[0]['total'] if total_result else 0
                
                return {
                    'company_id': company_id,
                    'total_count': total_count,
                    'is_single_company': True
                }
            else:
                # å…¨ä½“çµ±è¨ˆ
                total_query = "SELECT COUNT(*) as total FROM search_history"
                total_result = fetch_dict(total_query)
                total_count = total_result[0]['total'] if total_result else 0
                
                # ä¼æ¥­åˆ¥çµ±è¨ˆ
                company_query = "SELECT company_id, COUNT(*) as count FROM search_history GROUP BY company_id ORDER BY count DESC"
                company_results = fetch_dict(company_query)
                
                return {
                    'total_count': total_count,
                    'companies': company_results,
                    'is_single_company': False
                }
                
        except Exception as e:
            print(f"[ERROR] çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'total_count': 0, 'companies': [], 'is_single_company': False}
    
    def preview_deletion(self, days=30, company_id=None):
        """
        å‰Šé™¤å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        
        Args:
            days (int): å‰Šé™¤å¯¾è±¡ã®æ—¥æ•°
            company_id (str, optional): å¯¾è±¡ä¼æ¥­ID
            
        Returns:
            dict: ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±
        """
        try:
            cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
            
            if company_id:
                if self.db_type == "postgresql":
                    count_query = "SELECT COUNT(*) as count FROM search_history WHERE company_id = %s AND created_at < %s"
                    sample_query = "SELECT question, created_at FROM search_history WHERE company_id = %s AND created_at < %s ORDER BY created_at DESC LIMIT 5"
                    params = (company_id, cutoff_date)
                else:
                    count_query = "SELECT COUNT(*) as count FROM search_history WHERE company_id = ? AND created_at < ?"
                    sample_query = "SELECT question, created_at FROM search_history WHERE company_id = ? AND created_at < ? ORDER BY created_at DESC LIMIT 5"
                    params = (company_id, cutoff_date)
            else:
                if self.db_type == "postgresql":
                    count_query = "SELECT COUNT(*) as count FROM search_history WHERE created_at < %s"
                    sample_query = "SELECT company_id, question, created_at FROM search_history WHERE created_at < %s ORDER BY created_at DESC LIMIT 10"
                    params = (cutoff_date,)
                else:
                    count_query = "SELECT COUNT(*) as count FROM search_history WHERE created_at < ?"
                    sample_query = "SELECT company_id, question, created_at FROM search_history WHERE created_at < ? ORDER BY created_at DESC LIMIT 10"
                    params = (cutoff_date,)
            
            # å‰Šé™¤å¯¾è±¡ä»¶æ•°
            count_result = fetch_dict(count_query, params)
            deletion_count = count_result[0]['count'] if count_result else 0
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            sample_result = fetch_dict(sample_query, params)
            
            return {
                'deletion_count': deletion_count,
                'cutoff_date': cutoff_date,
                'sample_data': sample_result,
                'days': days
            }
            
        except Exception as e:
            print(f"[ERROR] ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            return {'deletion_count': 0, 'sample_data': []}
    
    def backup_before_deletion(self, backup_file, days=30, company_id=None):
        """
        å‰Šé™¤å‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
        
        Args:
            backup_file (str): ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            days (int): ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ã®æ—¥æ•°
            company_id (str, optional): å¯¾è±¡ä¼æ¥­ID
            
        Returns:
            bool: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            import csv
            
            cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
            
            if company_id:
                if self.db_type == "postgresql":
                    backup_query = """
                        SELECT company_id, user_info, question, answer, input_tokens, output_tokens, created_at 
                        FROM search_history 
                        WHERE company_id = %s AND created_at < %s 
                        ORDER BY created_at DESC
                    """
                    params = (company_id, cutoff_date)
                else:
                    backup_query = """
                        SELECT company_id, user_info, question, answer, input_tokens, output_tokens, created_at 
                        FROM search_history 
                        WHERE company_id = ? AND created_at < ? 
                        ORDER BY created_at DESC
                    """
                    params = (company_id, cutoff_date)
            else:
                if self.db_type == "postgresql":
                    backup_query = """
                        SELECT company_id, user_info, question, answer, input_tokens, output_tokens, created_at 
                        FROM search_history 
                        WHERE created_at < %s 
                        ORDER BY created_at DESC
                    """
                    params = (cutoff_date,)
                else:
                    backup_query = """
                        SELECT company_id, user_info, question, answer, input_tokens, output_tokens, created_at 
                        FROM search_history 
                        WHERE created_at < ? 
                        ORDER BY created_at DESC
                    """
                    params = (cutoff_date,)
            
            backup_data = fetch_dict(backup_query, params)
            
            if not backup_data:
                print("[INFO] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return True
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(backup_file, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['company_id', 'user_info', 'question', 'answer', 'input_tokens', 'output_tokens', 'created_at']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                writer.writeheader()
                for row in backup_data:
                    writer.writerow(row)
            
            print(f"[SUCCESS] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {len(backup_data)}ä»¶ â†’ {backup_file}")
            return True
            
        except Exception as e:
            print(f"[ERROR] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def delete_old_history(self, days=30, company_id=None, backup_file=None):
        """
        å¤ã„æ¤œç´¢å±¥æ­´ã‚’å‰Šé™¤
        
        Args:
            days (int): å‰Šé™¤å¯¾è±¡ã®æ—¥æ•° (ã“ã®æ—¥æ•°ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤)
            company_id (str, optional): å¯¾è±¡ä¼æ¥­ID
            backup_file (str, optional): å‰Šé™¤å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«
            
        Returns:
            dict: å‰Šé™¤çµæœ
        """
        try:
            # å‰Šé™¤å‰ã®çµ±è¨ˆå–å¾—
            before_stats = self.get_statistics(company_id)
            self.stats['total_before'] = before_stats.get('total_count', 0)
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            if backup_file:
                print(f"[BACKUP] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ã„ã¾ã™: {backup_file}")
                if not self.backup_before_deletion(backup_file, days, company_id):
                    print("[ERROR] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‰Šé™¤ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
                    return {'success': False, 'error': 'backup_failed'}
            
            # å‰Šé™¤å®Ÿè¡Œ
            cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
            print(f"[DELETE] {cutoff_date} ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ä¸­...")
            
            if company_id:
                if self.db_type == "postgresql":
                    delete_query = "DELETE FROM search_history WHERE company_id = %s AND created_at < %s"
                    params = (company_id, cutoff_date)
                else:
                    delete_query = "DELETE FROM search_history WHERE company_id = ? AND created_at < ?"
                    params = (company_id, cutoff_date)
            else:
                if self.db_type == "postgresql":
                    delete_query = "DELETE FROM search_history WHERE created_at < %s"
                    params = (cutoff_date,)
                else:
                    delete_query = "DELETE FROM search_history WHERE created_at < ?"
                    params = (cutoff_date,)
            
            # å‰Šé™¤å®Ÿè¡Œ
            deleted_count = execute_query(delete_query, params)
            
            # å‰Šé™¤å¾Œã®çµ±è¨ˆå–å¾—
            after_stats = self.get_statistics(company_id)
            self.stats['total_after'] = after_stats.get('total_count', 0)
            self.stats['deleted_count'] = self.stats['total_before'] - self.stats['total_after']
            
            result = {
                'success': True,
                'deleted_count': self.stats['deleted_count'],
                'before_count': self.stats['total_before'],
                'after_count': self.stats['total_after'],
                'cutoff_date': cutoff_date,
                'days': days,
                'company_id': company_id,
                'backup_file': backup_file
            }
            
            return result
            
        except Exception as e:
            print(f"[ERROR] å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="æ¤œç´¢å±¥æ­´å‰Šé™¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # 30æ—¥ã‚ˆã‚Šå¤ã„å±¥æ­´ã‚’ã™ã¹ã¦å‰Šé™¤ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚ã‚Šï¼‰
  python cleanup_search_history.py --days 30
  
  # ç‰¹å®šä¼æ¥­ã®90æ—¥ã‚ˆã‚Šå¤ã„å±¥æ­´ã‚’å‰Šé™¤
  python cleanup_search_history.py --days 90 --company demo-company
  
  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãã§å‰Šé™¤
  python cleanup_search_history.py --days 30 --backup backup_20250813.csv
  
  # ç¾åœ¨ã®çµ±è¨ˆã®ã¿è¡¨ç¤º
  python cleanup_search_history.py --stats-only
  
  # å‰Šé™¤å¯¾è±¡ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿
  python cleanup_search_history.py --days 30 --preview-only
        """
    )
    
    parser.add_argument("--days", "-d", type=int, default=30, 
                      help="å‰Šé™¤å¯¾è±¡ã®æ—¥æ•°ï¼ˆã“ã®æ—¥æ•°ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥ï¼‰")
    parser.add_argument("--company", "-c", type=str, 
                      help="å¯¾è±¡ä¼æ¥­IDï¼ˆçœç•¥æ™‚ã¯å…¨ä¼æ¥­ï¼‰")
    parser.add_argument("--backup", "-b", type=str, 
                      help="å‰Šé™¤å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--force", "-f", action="store_true", 
                      help="ç¢ºèªãªã—ã§å®Ÿè¡Œ")
    parser.add_argument("--stats-only", action="store_true", 
                      help="ç¾åœ¨ã®çµ±è¨ˆã®ã¿è¡¨ç¤º")
    parser.add_argument("--preview-only", action="store_true", 
                      help="å‰Šé™¤å¯¾è±¡ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿è¡¨ç¤º")
    
    args = parser.parse_args()
    
    cleanup = SearchHistoryCleanup()
    
    # çµ±è¨ˆã®ã¿è¡¨ç¤º
    if args.stats_only:
        print("=" * 50)
        print("ğŸ“Š æ¤œç´¢å±¥æ­´çµ±è¨ˆæƒ…å ±")
        print("=" * 50)
        
        stats = cleanup.get_statistics(args.company)
        
        if args.company:
            print(f"ä¼æ¥­ID: {args.company}")
            print(f"ç·å±¥æ­´ä»¶æ•°: {stats['total_count']:,}ä»¶")
        else:
            print(f"ç·å±¥æ­´ä»¶æ•°: {stats['total_count']:,}ä»¶")
            print("\nä¼æ¥­åˆ¥å†…è¨³:")
            for company in stats['companies'][:10]:
                print(f"  {company['company_id']}: {company['count']:,}ä»¶")
        
        return
    
    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿è¡¨ç¤º
    if args.preview_only:
        print("=" * 50)
        print(f"ğŸ” å‰Šé™¤å¯¾è±¡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ({args.days}æ—¥ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿)")
        print("=" * 50)
        
        preview = cleanup.preview_deletion(args.days, args.company)
        
        print(f"å‰Šé™¤å¯¾è±¡ä»¶æ•°: {preview['deletion_count']:,}ä»¶")
        print(f"å‰Šé™¤åŸºæº–æ—¥æ™‚: {preview['cutoff_date']}")
        
        if preview['sample_data']:
            print("\nå‰Šé™¤å¯¾è±¡ã‚µãƒ³ãƒ—ãƒ«:")
            for i, sample in enumerate(preview['sample_data'][:5], 1):
                if args.company:
                    print(f"  {i}. [{sample['created_at']}] {sample['question'][:50]}...")
                else:
                    print(f"  {i}. [{sample['created_at']}] [{sample['company_id']}] {sample['question'][:50]}...")
        
        return
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†
    print("=" * 50)
    print("ğŸ§¹ æ¤œç´¢å±¥æ­´ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    # ç¾åœ¨ã®çŠ¶æ³è¡¨ç¤º
    current_stats = cleanup.get_statistics(args.company)
    print(f"ç¾åœ¨ã®å±¥æ­´ä»¶æ•°: {current_stats['total_count']:,}ä»¶")
    
    # å‰Šé™¤å¯¾è±¡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    preview = cleanup.preview_deletion(args.days, args.company)
    print(f"å‰Šé™¤å¯¾è±¡: {preview['deletion_count']:,}ä»¶ ({args.days}æ—¥ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿)")
    
    if preview['deletion_count'] == 0:
        print("âœ… å‰Šé™¤å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ç¢ºèª
    if not args.force:
        target_desc = f"ä¼æ¥­ã€Œ{args.company}ã€ã®" if args.company else "å…¨ä¼æ¥­ã®"
        backup_desc = f" (ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {args.backup})" if args.backup else ""
        
        print(f"\nâš ï¸  {target_desc}{preview['deletion_count']:,}ä»¶ã®å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™{backup_desc}")
        confirm = input("å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
        if confirm.lower() != 'y':
            print("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
            return
    
    # å‰Šé™¤å®Ÿè¡Œ
    print(f"\nğŸ—‘ï¸  å‰Šé™¤ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...")
    result = cleanup.delete_old_history(args.days, args.company, args.backup)
    
    if result['success']:
        print(f"âœ… å‰Šé™¤å®Œäº†!")
        print(f"   å‰Šé™¤ä»¶æ•°: {result['deleted_count']:,}ä»¶")
        print(f"   å‰Šé™¤å‰: {result['before_count']:,}ä»¶")
        print(f"   å‰Šé™¤å¾Œ: {result['after_count']:,}ä»¶")
        
        if result['backup_file']:
            print(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {result['backup_file']}")
    else:
        print(f"âŒ å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")

if __name__ == "__main__":
    main()