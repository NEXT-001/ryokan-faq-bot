"""
ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹ - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’æä¾›
chat_service.py
"""
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os
import streamlit as st
import urllib.parse
import openai
import re
from dotenv import load_dotenv
from config.unified_config import UnifiedConfig
from services.embedding_service import get_embedding
from services.line_service import send_line_message  # LINEé€ä¿¡æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.faq_migration import get_faq_data_from_db, init_faq_migration
from services.tourism_service import detect_language, generate_tourism_response_by_city
from services.translation_service import TranslationService

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# é¡ä¼¼åº¦ã®ã—ãã„å€¤ï¼ˆã“ã‚Œã‚’ä¸‹å›ã‚‹å ´åˆã¯ä¸æ˜ç¢ºãªå›ç­”ã¨ãªã‚‹ï¼‰
SIMILARITY_THRESHOLD = 0.6
# éå¸¸ã«ä½ã„é¡ä¼¼åº¦ã®ã—ãã„å€¤ï¼ˆã“ã®å ´åˆã¯LINEé€šçŸ¥ã‚’é€ã‚‹ï¼‰
LOW_SIMILARITY_THRESHOLD = 0.4

def add_bing_links_to_brackets(text):
    """
    FAQå›ç­”å†…ã®[å˜èª]å½¢å¼ã®æ–‡å­—åˆ—ã«Bingæ¤œç´¢ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
    ä¾‹: [é‡‘é–£å¯º] â†’ [é‡‘é–£å¯º](https://www.bing.com/search?q=é‡‘é–£å¯º)
    """
    def replace_bracket_with_link(match):
        word = match.group(1)  # [ã¨]ã®é–“ã®æ–‡å­—ã‚’å–å¾—
        encoded_word = urllib.parse.quote(word)
        bing_url = f"https://www.bing.com/search?q={encoded_word}"
        return f"[{word}]({bing_url})"
    
    # [æ–‡å­—åˆ—]ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’Markdownãƒªãƒ³ã‚¯ã«å¤‰æ›
    pattern = r'\[([^\[\]]+)\]'
    result = re.sub(pattern, replace_bracket_with_link, text)
    
    return result

def get_response(user_input, company_id=None, user_info=""):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«å¯¾ã™ã‚‹æœ€é©ãªå›ç­”ã‚’å–å¾—ã™ã‚‹
    
    Args:
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•
        company_id (str, optional): ä¼šç¤¾IDï¼ˆæŒ‡å®šãŒãªã„å ´åˆã¯ãƒ‡ãƒ¢ä¼æ¥­ï¼‰
        user_info (str, optional): ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ï¼ˆãŠéƒ¨å±‹ç•ªå·ãªã©ï¼‰
        
    Returns:
        tuple: (å›ç­”, å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°, å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°)
    """
    # ä¼šç¤¾IDãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ¢ä¼æ¥­ã‚’ä½¿ç”¨
    if not company_id:
        company_id = "demo-company"
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
    if UnifiedConfig.is_test_mode():
        print(f"ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­ - ä¼šç¤¾ID: {company_id}")
        # ãƒ†ã‚¹ãƒˆç”¨ã®å›ç­”ã‚»ãƒƒãƒˆ
        test_responses = {
            "ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³": "ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³ã¯15:00ã€œ19:00ã§ã™ã€‚äº‹å‰ã«ã”é€£çµ¡ã„ãŸã ã‘ã‚Œã°ã€é…ã„ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³ã«ã‚‚å¯¾å¿œå¯èƒ½ã§ã™ã€‚",
            "ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ": "ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆã¯10:00ã¨ãªã£ã¦ãŠã‚Šã¾ã™ã€‚ãƒ¬ã‚¤ãƒˆãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆã‚’ã”å¸Œæœ›ã®å ´åˆã¯ã€ãƒ•ãƒ­ãƒ³ãƒˆã«ã”ç›¸è«‡ãã ã•ã„ã€‚",
            "é§è»Šå ´": "ã¯ã„ã€ç„¡æ–™ã®é§è»Šå ´ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚å¤§å‹è»Šã®å ´åˆã¯äº‹å‰ã«ã”é€£çµ¡ãã ã•ã„ã€‚",
            "wi-fi": "å…¨å®¢å®¤ã§Wi-Fiã‚’ç„¡æ–™ã§ã”åˆ©ç”¨ã„ãŸã ã‘ã¾ã™ã€‚æ¥ç¶šæƒ…å ±ã¯ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³æ™‚ã«ãŠæ¸¡ã—ã—ã¾ã™ã€‚",
            "ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼": "ã¯ã„ã€ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ãŒã‚ã‚‹å ´åˆã¯äºˆç´„æ™‚ã«ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚å¯èƒ½ãªé™ã‚Šå¯¾å¿œã„ãŸã—ã¾ã™ã€‚",
            "éƒ¨å±‹": "å’Œå®¤ã¨æ´‹å®¤ã®ä¸¡æ–¹ã‚’ã”ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚å’Œå®¤ã¯8ç•³ãƒ»10ç•³ãƒ»12ç•³ã€æ´‹å®¤ã¯ã‚·ãƒ³ã‚°ãƒ«ãƒ»ãƒ„ã‚¤ãƒ³ãƒ»ãƒ€ãƒ–ãƒ«ãŒã”ã–ã„ã¾ã™ã€‚",
            "æ¸©æ³‰": "å½“é¤¨ã®æ¸©æ³‰ã¯ç¥çµŒç—›ã€ç­‹è‚‰ç—›ã€é–¢ç¯€ç—›ã€äº”åè‚©ã€é‹å‹•éº»ç—ºã€é–¢ç¯€ã®ã“ã‚ã°ã‚Šã€ã†ã¡ã¿ã€ãã˜ãã€æ…¢æ€§æ¶ˆåŒ–å™¨ç—…ã€ç—”ç–¾ã€å†·ãˆæ€§ã€ç—…å¾Œå›å¾©æœŸã€ç–²åŠ´å›å¾©ã€å¥åº·å¢—é€²ã«åŠ¹æœãŒã‚ã‚Šã¾ã™ã€‚",
            "é£Ÿäº‹": "åœ°å…ƒã®æ–°é®®ãªé£Ÿæã‚’ä½¿ã£ãŸä¼šå¸­æ–™ç†ã‚’ã”æä¾›ã—ã¦ã„ã¾ã™ã€‚æœé£Ÿã¯å’Œé£Ÿã¾ãŸã¯æ´‹é£Ÿã‹ã‚‰ãŠé¸ã³ã„ãŸã ã‘ã¾ã™ã€‚",
            "å­ä¾›": "ã¯ã„ã€ãŠå­æ§˜é€£ã‚Œã®ãŠå®¢æ§˜ã‚‚å¤§æ­“è¿ã§ã™ã€‚ãŠå­æ§˜ç”¨ã®æµ´è¡£ã‚„ã‚¹ãƒªãƒƒãƒ‘ã€é£Ÿäº‹ç”¨ã®æ¤…å­ã‚‚ã”ç”¨æ„ã—ã¦ãŠã‚Šã¾ã™ã€‚",
            "è¦³å…‰": "å½“é¤¨ã‹ã‚‰è»Šã§15åˆ†ä»¥å†…ã«ã€â—‹â—‹ç¥ç¤¾ã€â–³â–³ç¾è¡“é¤¨ã€â–¡â–¡å…¬åœ’ãªã©ãŒã”ã–ã„ã¾ã™ã€‚è©³ã—ã„æƒ…å ±ã¯ãƒ•ãƒ­ãƒ³ãƒˆã§ã”æ¡ˆå†…ã—ã¦ãŠã‚Šã¾ã™ã€‚"
        }
        
        # ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for keyword, response in test_responses.items():
            if keyword in user_input:
                return response, len(user_input.split()), len(response.split())
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å›ç­”
        default_response = (
            "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ãã®è³ªå•ã«ã¤ã„ã¦ã¯æ‹…å½“è€…ã«ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
            "ã—ã°ã‚‰ããŠå¾…ã¡ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚\n\n"
            "I apologize, but I need to check with our staff regarding that question. "
            "Could you please wait a moment?"
        )
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã‚‚LINEé€šçŸ¥ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        print(f"ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã™ - ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±: {user_info}, è³ªå•: {user_input}")
        
        return default_response, len(user_input.split()), len(default_response.split())
    
    # æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ - DBã‹ã‚‰FAQãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    try:
        # FAQãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆæœŸåŒ–
        init_faq_migration()
        
        # DBã‹ã‚‰FAQãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        faq_data = get_faq_data_from_db(company_id)
        
        if not faq_data:
            # DBã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã€å¾“æ¥ã®PKLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã‚’è©¦è¡Œ
            company_path = os.path.join(UnifiedConfig.get_data_path(), "companies", company_id)
            faq_path = os.path.join(company_path, "faq_with_embeddings.pkl")
            
            if os.path.exists(faq_path):
                # PKLãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯èª­ã¿è¾¼ã¿ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
                df = pd.read_pickle(faq_path)
                print(f"PKL FAQ ãƒ‡ãƒ¼ã‚¿ï¼ˆå¾Œæ–¹äº’æ›ï¼‰: {len(df)} ä»¶")
                
                # ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ç§»è¡Œ
                from services.faq_migration import migrate_company_faq_data
                if migrate_company_faq_data(company_id, show_progress=False):
                    print(f"PKLãƒ‡ãƒ¼ã‚¿ã‚’DBã«ç§»è¡Œã—ã¾ã—ãŸ: {company_id}")
                    # ç§»è¡Œå¾Œã«DBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—
                    faq_data = get_faq_data_from_db(company_id)
                else:
                    # ç§»è¡Œã«å¤±æ•—ã—ãŸå ´åˆã¯PKLãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ç”¨
                    faq_data = df.to_dict('records')
                    for i, row in enumerate(faq_data):
                        row['id'] = i + 1
            else:
                error_msg = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ä¼æ¥­IDã€Œ{company_id}ã€ã®FAQãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                return error_msg, 0, 0
        
        print(f"FAQ ãƒ‡ãƒ¼ã‚¿: {len(faq_data)} ä»¶")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—
        user_embedding = get_embedding(user_input)
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒå­˜åœ¨ã™ã‚‹FAQã®ã¿ã‚’æŠ½å‡º
        valid_faqs = [faq for faq in faq_data if faq['embedding'] is not None]
        
        if not valid_faqs:
            error_msg = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ä¼æ¥­IDã€Œ{company_id}ã€ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            return error_msg, 0, 0
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®è¨ˆç®—
        embeddings_list = [faq['embedding'] for faq in valid_faqs]
        similarities = cosine_similarity([user_embedding], embeddings_list)
        
        # é¡ä¼¼åº¦ã®ä¸Šä½5ä»¶ã‚’è¡¨ç¤º
        top_indices = np.argsort(similarities[0])[::-1][:5]
        print("\nä¸Šä½5ä»¶ã®é¡ä¼¼è³ªå•:")
        for idx in top_indices:
            if idx < len(valid_faqs):
                print(f"é¡ä¼¼åº¦: {similarities[0][idx]:.4f}, è³ªå•: {valid_faqs[idx]['question'][:50]}...")
        
        # æœ€ã‚‚é¡ä¼¼åº¦ã®é«˜ã„è³ªå•ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        best_idx = np.argmax(similarities)
        similarity_score = similarities[0][best_idx]
        
        print(f"\næœ€ã‚‚é¡ä¼¼åº¦ã®é«˜ã„è³ªå•: {valid_faqs[best_idx]['question']}")
        print(f"é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {similarity_score:.4f}")
        
        # å¯¾å¿œã™ã‚‹å›ç­”ã‚’å–å¾—
        answer = valid_faqs[best_idx]["answer"]
        
        # FAQå›ç­”å†…ã®[å˜èª]ã«Bingãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
        answer = add_bing_links_to_brackets(answer)
        
        user_lang = detect_language(user_input)
        print(f"è³ªå•ã—ãŸè¨€èª: {user_lang}")
        
        # å¤–å›½èªã®è³ªå•ã®å ´åˆã¯å›ç­”ã‚’ç¿»è¨³
        if user_lang != 'ja':
            translation_service = TranslationService()
            # è©³ç´°æƒ…å ±ãƒªãƒ³ã‚¯ã¯æ—¥æœ¬èªã®ã¾ã¾ä¿æŒã—ã€èª¬æ˜æ–‡ã®ã¿ç¿»è¨³
            translated_answer = translation_service.translate_text(answer, user_lang, 'ja')
            # ãƒªãƒ³ã‚¯éƒ¨åˆ†ã¯æ—¥æœ¬èªã®ã¾ã¾ä¿æŒã™ã‚‹ãŸã‚ã€å…ƒã®å›ç­”ã¨ç¿»è¨³ã•ã‚ŒãŸå›ç­”ã‚’é©åˆ‡ã«çµåˆ
            answer = _preserve_japanese_links_in_translation(answer, translated_answer)
            print(f"å›ç­”ã‚’{user_lang}ã«ç¿»è¨³ã—ã¾ã—ãŸ")
        
        # é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãŒä½ã™ãã‚‹å ´åˆ
        if similarity_score < SIMILARITY_THRESHOLD:
            # # éå¸¸ã«ä½ã„é¡ä¼¼åº¦ã®å ´åˆ
            # LINEé€šçŸ¥ã‚’é€ä¿¡
            print(f"é¡ä¼¼åº¦ãŒä½ã„ãŸã‚ã€LINEé€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã™: {similarity_score:.4f}")
            send_line_message(
                question=user_input,
                answer="é©åˆ‡ãªå›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\nç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ãã®è³ªå•ã«ã¤ã„ã¦ã¯æ‹…å½“è€…ã«ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",
                similarity_score=similarity_score,
                room_number=user_info,
                company_id=company_id
            )
            
            # è¦³å…‰ãƒ»ã‚°ãƒ«ãƒ¡é–¢é€£è³ªå•ã®å ´åˆã€ãã‚‹ãªã³æ¤œç´¢ã‚’ææ¡ˆ
            if _is_restaurant_query(user_input):
                answer = _generate_gnavi_response(user_input, user_lang)
            else:
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚è¨€èªã«å¿œã˜ã¦ç¿»è¨³
                if user_lang == 'en':
                    answer = "I apologize, but I need to check with our staff regarding that question. Could you please wait a moment?"
                elif user_lang == 'ko':
                    answer = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë‹´ë‹¹ìì—ê²Œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹œê² ì–´ìš”?"
                elif user_lang == 'zh':
                    answer = "å¾ˆæŠ±æ­‰ï¼Œå…³äºè¿™ä¸ªé—®é¢˜éœ€è¦ä¸å·¥ä½œäººå‘˜ç¡®è®¤ã€‚è¯·ç¨ç­‰ç‰‡åˆ»ã€‚"
                else:
                    answer = (
                        "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ãã®è³ªå•ã«ã¤ã„ã¦ã¯æ‹…å½“è€…ã«ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
                        "ã—ã°ã‚‰ããŠå¾…ã¡ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
                    )

        return answer, len(user_input.split()), len(answer.split())
    
    except Exception as e:
        print(f"å›ç­”å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¹ã‚¿ãƒƒãƒ•ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
        
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚LINEé€šçŸ¥
        try:
            send_line_message(
                question=user_input,
                answer=f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                similarity_score=0.0,
                room_number=user_info,
                company_id=company_id
            )
        except Exception as line_error:
            print(f"LINEé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {line_error}")
        
        return error_message, 0, 0


def _preserve_japanese_links_in_translation(original_text: str, translated_text: str) -> str:
    """
    ç¿»è¨³ã•ã‚ŒãŸå›ç­”ã®ä¸­ã§ã€æ—¥æœ¬èªã®è©³ç´°æƒ…å ±ãƒªãƒ³ã‚¯ã‚’ä¿æŒã™ã‚‹
    
    Args:
        original_text: å…ƒã®æ—¥æœ¬èªå›ç­”
        translated_text: ç¿»è¨³ã•ã‚ŒãŸå›ç­”
        
    Returns:
        str: æ—¥æœ¬èªãƒªãƒ³ã‚¯ãŒä¿æŒã•ã‚ŒãŸç¿»è¨³æ¸ˆã¿å›ç­”
    """
    import re
    
    # è©³ç´°æƒ…å ±ãƒªãƒ³ã‚¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
    link_patterns = [
        r'ğŸ“\s*è©³ç´°æƒ…å ±[ï¼š:][^ã€‘]*',
        r'ğŸ—¾\s*è¦³å…‰æƒ…å ±[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]',
        r'ğŸ—ºï¸\s*åœ°å›³æƒ…å ±[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]',
        r'ğŸ“–\s*[^ï¼ˆ\(]*[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]',
        r'ğŸ½ï¸\s*[^ï¼ˆ\(]*[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]'
    ]
    
    # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ—¥æœ¬èªãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
    japanese_links = []
    for pattern in link_patterns:
        matches = re.findall(pattern, original_text)
        japanese_links.extend(matches)
    
    # ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®æœ«å°¾ã«æ—¥æœ¬èªã®è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
    if japanese_links and 'ğŸ“' not in translated_text:
        translated_text += "\n\nğŸ“ è©³ç´°æƒ…å ±:\n"
        for link in japanese_links:
            if link not in translated_text:
                translated_text += f"â€¢ {link}\n"
    
    return translated_text


def _is_restaurant_query(query: str) -> bool:
    """
    è³ªå•ãŒãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ãƒ»ã‚°ãƒ«ãƒ¡é–¢é€£ã‹ã‚’åˆ¤å®š
    """
    restaurant_keywords = [
        "ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "é£Ÿäº‹", "ã‚°ãƒ«ãƒ¡", "ãƒ©ãƒ³ãƒ", "ãƒ‡ã‚£ãƒŠãƒ¼", "é£²é£Ÿ", "æ–™ç†", 
        "ã‚«ãƒ•ã‚§", "å±…é…’å±‹", "é£Ÿã¹ç‰©", "ç¾å‘³ã—ã„", "ãŠã™ã™ã‚", "é£Ÿã¹ã‚‹",
        "restaurant", "food", "eat", "dinner", "lunch", "cafe", "gourmet",
        "ë§›ì§‘", "ìŒì‹", "ì‹ë‹¹", "ë ˆìŠ¤í† ë‘", "ì¹´í˜", "ë¨¹ë‹¤",
        "é¤å…", "ç¾é£Ÿ", "åƒ", "æ–™ç†", "å’–å•¡å…"
    ]
    return any(keyword in query.lower() for keyword in restaurant_keywords)


def _generate_gnavi_response(query: str, user_lang: str) -> str:
    """
    ãã‚‹ãªã³æ¤œç´¢æ¡ˆå†…ã®å¤šè¨€èªå¯¾å¿œãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ¡ˆå†…æ–‡
    default_responses = {
        "ja": "å‘¨è¾ºã®ãŠã™ã™ã‚ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã¯ã“ã¡ã‚‰ã§ã™ã€‚ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯ã‚’ã”å‚ç…§ãã ã•ã„ã€‚",
        "en": "Here are recommended restaurants in the area. Please refer to the link below.",
        "ko": "ì£¼ë³€ ì¶”ì²œ ë ˆìŠ¤í† ë‘ì€ ì—¬ê¸° ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ë§í¬ë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”.",
        "zh": "è¿™é‡Œæ˜¯å‘¨è¾¹æ¨èé¤å…ã€‚è¯·å‚è€ƒä»¥ä¸‹é“¾æ¥ã€‚"
    }
    
    base_text = default_responses.get(user_lang, default_responses["ja"])
    
    # OpenAI APIãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ç¿»è¨³ã‚’è©¦è¡Œ
    if openai.api_key:
        try:
            language_instruction = {
                "ja": "æ¬¡ã®æ–‡ç« ã‚’æ—¥æœ¬èªã§è‡ªç„¶ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
                "en": "Please output the following sentence naturally in English.",
                "ko": "ë‹¤ìŒ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.",
                "zh": "è¯·ç”¨è‡ªç„¶çš„ä¸­æ–‡è¾“å‡ºä»¥ä¸‹å¥å­ã€‚"
            }.get(user_lang, "Please output the following sentence naturally in English.")
            
            prompt = f"{language_instruction}\n\n{base_text}"
            
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=100
            )
            base_text = response['choices'][0]['message']['content']
        except Exception as e:
            print(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã‚‹ãªã³æ¤œç´¢URLç”Ÿæˆï¼ˆã‚¯ã‚¨ãƒªã‹ã‚‰å ´æ‰€ã‚’æŠ½å‡ºã¾ãŸã¯æ—¢å®šå€¤ã‚’ä½¿ç”¨ï¼‰
    location_param = "ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³"
    gnavi_url = f"https://www.gnavi.co.jp/search/k/?word={urllib.parse.quote(location_param)}"
    
    return f"**{base_text}**\n\nğŸ‘‰ [ãã‚‹ãªã³ã§ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã‚’è¦‹ã‚‹]({gnavi_url})"