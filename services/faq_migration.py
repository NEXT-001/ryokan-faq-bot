"""
FAQãƒ‡ãƒ¼ã‚¿ã¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®SQLiteç§»è¡Œã‚µãƒ¼ãƒ“ã‚¹
services/faq_migration.py
"""
import os
import pandas as pd
import numpy as np
import pickle
import sqlite3
from datetime import datetime
from core.database import (
    get_db_connection, execute_query, fetch_dict, fetch_dict_one,
    initialize_database, table_exists
)
from config.unified_config import UnifiedConfig

def create_faq_tables():
    """FAQã¨ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # FAQãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ—¢å­˜ã®faq_dataãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ‹¡å¼µï¼‰
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS faq_embeddings (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    faq_id INTEGER NOT NULL,
                    embedding_vector BLOB NOT NULL,
                    vector_model TEXT DEFAULT 'voyage-3',
                    embedding_dim INTEGER DEFAULT 1024,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (faq_id) REFERENCES faq_data (id) ON DELETE CASCADE
                )
            """)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_faq_embeddings_faq_id ON faq_embeddings(faq_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_faq_embeddings_model ON faq_embeddings(vector_model)")
            
            conn.commit()
            print("[MIGRATION] FAQé–¢é€£ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")
            return True
            
    except Exception as e:
        print(f"[MIGRATION] ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def serialize_embedding(embedding_vector):
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒã‚¤ãƒŠãƒªã«ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
    try:
        if isinstance(embedding_vector, list):
            embedding_vector = np.array(embedding_vector, dtype=np.float32)
        elif isinstance(embedding_vector, np.ndarray):
            embedding_vector = embedding_vector.astype(np.float32)
        
        return embedding_vector.tobytes()
    except Exception as e:
        print(f"[MIGRATION] ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def deserialize_embedding(binary_data):
    """ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
    try:
        return np.frombuffer(binary_data, dtype=np.float32).tolist()
    except Exception as e:
        print(f"[MIGRATION] ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚¨ãƒ©ãƒ¼: {e}")
        return None

def migrate_company_faq_data(company_id, show_progress=False):
    """æŒ‡å®šã•ã‚ŒãŸä¼šç¤¾ã®FAQãƒ‡ãƒ¼ã‚¿ã‚’DBã«ç§»è¡Œ"""
    try:
        company_dir = UnifiedConfig.get_data_path(company_id)
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        csv_path = os.path.join(company_dir, "faq.csv")
        if not os.path.exists(csv_path):
            print(f"[MIGRATION] CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
            return False
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        pkl_path = os.path.join(company_dir, "faq_with_embeddings.pkl")
        has_embeddings = os.path.exists(pkl_path)
        
        if show_progress:
            import streamlit as st
            st.info(f"ğŸ“ {company_id} ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œä¸­...")
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if has_embeddings:
            try:
                df = pd.read_pickle(pkl_path)
                print(f"[MIGRATION] ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
            except Exception as e:
                print(f"[MIGRATION] PKLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                df = pd.read_csv(csv_path)
                has_embeddings = False
        else:
            df = pd.read_csv(csv_path)
            print(f"[MIGRATION] CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
        
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ç¢ºèª
        if 'question' not in df.columns or 'answer' not in df.columns:
            print("[MIGRATION] å¿…è¦ãªã‚«ãƒ©ãƒ (question, answer)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ï¼ˆå†ç§»è¡Œå¯¾å¿œï¼‰
        execute_query("DELETE FROM faq_data WHERE company_id = ?", (company_id,))
        print(f"[MIGRATION] æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤: {company_id}")
        
        # ãƒ‡ãƒ¼ã‚¿ç§»è¡Œå‡¦ç†
        total_count = len(df)
        success_count = 0
        
        for i, row in df.iterrows():
            try:
                # FAQåŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
                query = """
                    INSERT INTO faq_data (company_id, question, answer, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?)
                """
                current_time = datetime.now().isoformat()
                
                faq_cursor = get_db_connection().cursor()
                faq_cursor.execute(query, (
                    company_id,
                    row['question'],
                    row['answer'],
                    current_time,
                    current_time
                ))
                faq_id = faq_cursor.lastrowid
                faq_cursor.close()
                
                # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒã‚ã‚‹å ´åˆã¯ä¿å­˜
                if has_embeddings and 'embedding' in row and row['embedding'] is not None:
                    try:
                        serialized_embedding = serialize_embedding(row['embedding'])
                        if serialized_embedding:
                            embedding_query = """
                                INSERT INTO faq_embeddings 
                                (faq_id, embedding_vector, vector_model, embedding_dim, created_at, updated_at)
                                VALUES (?, ?, ?, ?, ?, ?)
                            """
                            execute_query(embedding_query, (
                                faq_id,
                                serialized_embedding,
                                'voyage-3',  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
                                len(row['embedding']) if isinstance(row['embedding'], (list, np.ndarray)) else 1024,
                                current_time,
                                current_time
                            ))
                    except Exception as e:
                        print(f"[MIGRATION] ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼ (FAQ ID: {faq_id}): {e}")
                
                success_count += 1
                
                # é€²è¡ŒçŠ¶æ³æ›´æ–°
                if show_progress:
                    progress = (i + 1) / total_count
                    progress_bar.progress(progress)
                    status_text.text(f"ç§»è¡Œä¸­: {i+1}/{total_count} ä»¶")
                
            except Exception as e:
                print(f"[MIGRATION] FAQç§»è¡Œã‚¨ãƒ©ãƒ¼ (è¡Œ {i}): {e}")
                continue
        
        # ä¼šç¤¾ã®FAQæ•°ã‚’æ›´æ–°
        from core.database import update_company_faq_count_in_db
        update_company_faq_count_in_db(company_id, success_count)
        
        if show_progress:
            progress_bar.progress(1.0)
            status_text.success(f"âœ… ç§»è¡Œå®Œäº†: {success_count}/{total_count} ä»¶")
        
        print(f"[MIGRATION] {company_id} ã®ç§»è¡Œå®Œäº†: {success_count}/{total_count} ä»¶")
        return True
        
    except Exception as e:
        print(f"[MIGRATION] ä¼šç¤¾ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return False

def migrate_all_companies(show_progress=False):
    """å…¨ä¼šç¤¾ã®FAQãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œ"""
    try:
        companies_dir = UnifiedConfig.COMPANIES_DIR
        if not os.path.exists(companies_dir):
            print("[MIGRATION] companiesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        # ä¼šç¤¾ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ã‚’å–å¾—
        company_ids = [d for d in os.listdir(companies_dir) 
                       if os.path.isdir(os.path.join(companies_dir, d))]
        
        if not company_ids:
            print("[MIGRATION] ç§»è¡Œå¯¾è±¡ã®ä¼šç¤¾ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return True
        
        if show_progress:
            import streamlit as st
            st.write(f"**ğŸ“Š {len(company_ids)} ç¤¾ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œã—ã¾ã™**")
            main_progress = st.progress(0)
            
        success_companies = []
        failed_companies = []
        
        for i, company_id in enumerate(company_ids):
            print(f"[MIGRATION] ç§»è¡Œé–‹å§‹: {company_id} ({i+1}/{len(company_ids)})")
            
            if migrate_company_faq_data(company_id, show_progress=False):
                success_companies.append(company_id)
            else:
                failed_companies.append(company_id)
            
            if show_progress:
                main_progress.progress((i + 1) / len(company_ids))
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        print(f"[MIGRATION] å…¨ä½“ç§»è¡Œå®Œäº†")
        print(f"[MIGRATION] æˆåŠŸ: {len(success_companies)} ç¤¾")
        print(f"[MIGRATION] å¤±æ•—: {len(failed_companies)} ç¤¾")
        
        if failed_companies:
            print(f"[MIGRATION] å¤±æ•—ã—ãŸä¼šç¤¾: {failed_companies}")
        
        if show_progress:
            import streamlit as st
            st.success(f"âœ… ç§»è¡Œå®Œäº†: æˆåŠŸ {len(success_companies)} ç¤¾, å¤±æ•— {len(failed_companies)} ç¤¾")
            if failed_companies:
                st.warning(f"å¤±æ•—ã—ãŸä¼šç¤¾: {', '.join(failed_companies)}")
        
        return len(failed_companies) == 0
        
    except Exception as e:
        print(f"[MIGRATION] å…¨ä½“ç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return False

def backup_original_data():
    """å…ƒã®CSV/PKLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    try:
        companies_dir = UnifiedConfig.COMPANIES_DIR
        backup_dir = os.path.join(UnifiedConfig.DATA_DIR, "backup_csv_pkl")
        
        if not os.path.exists(companies_dir):
            print("[MIGRATION] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return True
        
        os.makedirs(backup_dir, exist_ok=True)
        
        # å„ä¼šç¤¾ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        for company_id in os.listdir(companies_dir):
            company_path = os.path.join(companies_dir, company_id)
            if not os.path.isdir(company_path):
                continue
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            backup_company_dir = os.path.join(backup_dir, company_id)
            os.makedirs(backup_company_dir, exist_ok=True)
            
            # CSVã¨PKLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
            for filename in ['faq.csv', 'faq_with_embeddings.pkl']:
                src_path = os.path.join(company_path, filename)
                if os.path.exists(src_path):
                    import shutil
                    dst_path = os.path.join(backup_company_dir, filename)
                    shutil.copy2(src_path, dst_path)
                    print(f"[MIGRATION] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {src_path} -> {dst_path}")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_info_path = os.path.join(backup_dir, f"backup_info_{timestamp}.txt")
        with open(backup_info_path, 'w', encoding='utf-8') as f:
            f.write(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆæ—¥æ™‚: {datetime.now().isoformat()}\n")
            f.write(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ƒ: {companies_dir}\n")
            f.write(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆ: {backup_dir}\n")
        
        print(f"[MIGRATION] å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_dir}")
        return True
        
    except Exception as e:
        print(f"[MIGRATION] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def verify_migration(company_id):
    """ç§»è¡Œçµæœã‚’æ¤œè¨¼"""
    try:
        # DBã‹ã‚‰FAQãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        faq_query = "SELECT COUNT(*) FROM faq_data WHERE company_id = ?"
        faq_result = fetch_dict_one(faq_query, (company_id,))
        faq_count = faq_result['COUNT(*)'] if faq_result else 0
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ•°ã‚’å–å¾—
        embedding_query = """
            SELECT COUNT(*) FROM faq_embeddings fe 
            JOIN faq_data fd ON fe.faq_id = fd.id 
            WHERE fd.company_id = ?
        """
        embedding_result = fetch_dict_one(embedding_query, (company_id,))
        embedding_count = embedding_result['COUNT(*)'] if embedding_result else 0
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã¨æ¯”è¼ƒ
        company_dir = UnifiedConfig.get_data_path(company_id)
        csv_path = os.path.join(company_dir, "faq.csv")
        
        original_count = 0
        if os.path.exists(csv_path):
            try:
                df = pd.read_csv(csv_path)
                original_count = len(df)
            except Exception as e:
                print(f"[MIGRATION] å…ƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"[MIGRATION] æ¤œè¨¼çµæœ {company_id}:")
        print(f"  å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {original_count} ä»¶")
        print(f"  DB FAQ: {faq_count} ä»¶")
        print(f"  DB ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°: {embedding_count} ä»¶")
        
        return {
            'company_id': company_id,
            'original_count': original_count,
            'faq_count': faq_count,
            'embedding_count': embedding_count,
            'migration_success': faq_count == original_count
        }
        
    except Exception as e:
        print(f"[MIGRATION] æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_faq_data_from_db(company_id):
    """DBã‹ã‚‰FAQãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ä»˜ãï¼‰"""
    try:
        query = """
            SELECT 
                fd.id,
                fd.question,
                fd.answer,
                fd.created_at,
                fd.updated_at,
                fe.embedding_vector,
                fe.vector_model,
                fe.embedding_dim
            FROM faq_data fd
            LEFT JOIN faq_embeddings fe ON fd.id = fe.faq_id
            WHERE fd.company_id = ?
            ORDER BY fd.id
        """
        
        results = fetch_dict(query, (company_id,))
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º
        for result in results:
            if result['embedding_vector']:
                result['embedding'] = deserialize_embedding(result['embedding_vector'])
            else:
                result['embedding'] = None
            # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¯é™¤å»
            del result['embedding_vector']
        
        return results
        
    except Exception as e:
        print(f"[MIGRATION] FAQå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def save_faq_to_db(company_id, question, answer, embedding=None):
    """æ–°ã—ã„FAQã‚’DBã«ä¿å­˜"""
    try:
        # FAQåŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        faq_query = """
            INSERT INTO faq_data (company_id, question, answer, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?)
        """
        current_time = datetime.now().isoformat()
        
        cursor = get_db_connection().cursor()
        cursor.execute(faq_query, (company_id, question, answer, current_time, current_time))
        faq_id = cursor.lastrowid
        cursor.close()
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒã‚ã‚‹å ´åˆã¯ä¿å­˜
        if embedding is not None:
            serialized_embedding = serialize_embedding(embedding)
            if serialized_embedding:
                embedding_query = """
                    INSERT INTO faq_embeddings 
                    (faq_id, embedding_vector, vector_model, embedding_dim, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """
                execute_query(embedding_query, (
                    faq_id,
                    serialized_embedding,
                    'voyage-3',
                    len(embedding) if isinstance(embedding, (list, np.ndarray)) else 1024,
                    current_time,
                    current_time
                ))
        
        # FAQæ•°ã‚’æ›´æ–°
        from core.database import update_company_faq_count_in_db
        current_count = len(get_faq_data_from_db(company_id))
        update_company_faq_count_in_db(company_id, current_count)
        
        print(f"[MIGRATION] FAQä¿å­˜å®Œäº† (ID: {faq_id}): {question[:30]}...")
        return faq_id
        
    except Exception as e:
        print(f"[MIGRATION] FAQä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def update_faq_in_db(faq_id, question=None, answer=None, embedding=None):
    """æ—¢å­˜FAQã‚’æ›´æ–°"""
    try:
        current_time = datetime.now().isoformat()
        
        # FAQåŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        if question is not None or answer is not None:
            if question is not None and answer is not None:
                faq_query = "UPDATE faq_data SET question = ?, answer = ?, updated_at = ? WHERE id = ?"
                execute_query(faq_query, (question, answer, current_time, faq_id))
            elif question is not None:
                faq_query = "UPDATE faq_data SET question = ?, updated_at = ? WHERE id = ?"
                execute_query(faq_query, (question, current_time, faq_id))
            else:
                faq_query = "UPDATE faq_data SET answer = ?, updated_at = ? WHERE id = ?"
                execute_query(faq_query, (answer, current_time, faq_id))
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›´æ–°
        if embedding is not None:
            serialized_embedding = serialize_embedding(embedding)
            if serialized_embedding:
                # æ—¢å­˜ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ç¢ºèª
                check_query = "SELECT id FROM faq_embeddings WHERE faq_id = ?"
                existing = fetch_dict_one(check_query, (faq_id,))
                
                if existing:
                    # æ›´æ–°
                    embedding_query = """
                        UPDATE faq_embeddings 
                        SET embedding_vector = ?, embedding_dim = ?, updated_at = ?
                        WHERE faq_id = ?
                    """
                    execute_query(embedding_query, (
                        serialized_embedding,
                        len(embedding) if isinstance(embedding, (list, np.ndarray)) else 1024,
                        current_time,
                        faq_id
                    ))
                else:
                    # æ–°è¦ä½œæˆ
                    embedding_query = """
                        INSERT INTO faq_embeddings 
                        (faq_id, embedding_vector, vector_model, embedding_dim, created_at, updated_at)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """
                    execute_query(embedding_query, (
                        faq_id,
                        serialized_embedding,
                        'voyage-3',
                        len(embedding) if isinstance(embedding, (list, np.ndarray)) else 1024,
                        current_time,
                        current_time
                    ))
        
        print(f"[MIGRATION] FAQæ›´æ–°å®Œäº† (ID: {faq_id})")
        return True
        
    except Exception as e:
        print(f"[MIGRATION] FAQæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def delete_faq_from_db(faq_id):
    """FAQã‚’DBã‹ã‚‰å‰Šé™¤ï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚‚å«ã‚€ï¼‰"""
    try:
        # å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã«ã‚ˆã‚Šã€faq_embeddingsã¯è‡ªå‹•å‰Šé™¤ã•ã‚Œã‚‹
        execute_query("DELETE FROM faq_data WHERE id = ?", (faq_id,))
        print(f"[MIGRATION] FAQå‰Šé™¤å®Œäº† (ID: {faq_id})")
        return True
        
    except Exception as e:
        print(f"[MIGRATION] FAQå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        return False

# åˆæœŸåŒ–æ™‚ã«ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
def init_faq_migration():
    """FAQãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®åˆæœŸåŒ–"""
    try:
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        if not table_exists("companies"):
            initialize_database()
        
        # FAQé–¢é€£ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
        create_faq_tables()
        
        print("[MIGRATION] FAQãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Œäº†")
        return True
        
    except Exception as e:
        print(f"[MIGRATION] åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False